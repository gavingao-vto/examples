# Edge Development Concepts

This document provides a description of the Horizon Edge technology with more conceptual detail than the Quickstart guides.  Here you will learn about the reasoning behind the software development paradigm provided by the Horizon Edge.  You will see how Horizon very carefully safeguards anonymity and privacy until participants explicitly choose to share more (like their IP address, physical location, or other personally identifiable information).  You will see how the Horizon Edge works beneath the covers.  You will come to understand the major software components of the Horizon, their responsibilities, and how they interact to create Horizon Edge.  This document also details the interfaces provided by the major components that enable you to expose their internal state. It concludes with a discussion of software design considerations that are applicable in this environment. This document is recommended reading for all developers writing code for Horizon Edge machines.

Please note that if you are in a hurry, a more concise step-by-step Horizon "Edge Developer Quickstart Guide" to the development process is available here:
* [https://github.com/open-horizon/examples/blob/master/edge/doc/Edge-Developer-Quickstart-Guide.md](Edge-Developer-Quickstart-Guide.md)

To discuss the Horizon Edge development process, or to pose questions to the team, visit us at:
* [https://developer.ibm.com/answers/smart-spaces/17/internet-of-things.html](https://developer.ibm.com/answers/smart-spaces/17/internet-of-things.html)

The Horizon Edge is based upon the open source Horizon project:
* [https://github.com/open-horizon](https://github.com/open-horizon)

There are therefore several references to Horizon, and the "hzn" Linux shell command in this document.

## What is Horizon Edge?

Horizon Edge is a new approach to software deployment for machines at any edge or endpoint on the Internet.  Horizon Edge simplifies and secures large scale global deployment and maintenance of software on these edge machines.  Horizon Edge is designed specifically to foster fully-automated vendor-agnostic machine-to-machine collaboration.  It preserves the privacy and anonymity of devices and device owners right through the discovery process.  Only after all parties formally express their desire to engage can any private details be exchanged. Then all messaging between participants is secured against eavesdropping even by the message broker. The code is always deployed in a constrained sandbox, and only after its hash and cryptographic signature have been verified.

![Automated Deployment](images/Deployment.png)

Horizon Edge was designed to be almost completely decentralized to minimize risks that could impact the entire system.  Being decentralized means that as much as possible Horizon Edge avoids the use of any centralized services. The Horizon Exchange is an exception to this rule, providing centralized anonymous discovery, and secure message brokering services. If the Horizon Exchange is compromised machine-to-machine discovery could be impacted but machines that have already discovered each other would be unaffected.  A compromised Exchange could also impact message brokering, but due to the nature of Horizon's Future and Forward secrecy implementation a compromised broker would be unable to eavesdrop on any message between participants.  Centralizing the Exchange services was required for performance, but the Horizon design minimizes the ability of these centralized services to compromise other parts of the system.  The other major exception to complete decentralization is the need for one or more mutually agreeable cryptographic signing authorities as a basis for trust among any collaborating participants. If a trust source is compromised then only those participants using the specific trust source could be impacted.

![Mostly Decentralized](images/MostlyDecentralized.png)

Please note that Horizon Edge also fully supports the development of traditional Internet of Things (IoT) applications having many small IoT devices communicating with a centralized cloud service. That "Data Plane" side of the application would still be developed in the traditional manner (e.g., with IoT devices sending data to, and perhaps receiving commands from, the cloud).  However, the "Control Plane" side of this application could be fully automated by Horizon, and would greatly reduce the risks inherent in fully centralized designs.  On the Control Plane side Horizon will fully automate machine discovery, and will then fully manage the secure deployment, maintenance, and update of software on all of the IoT devices of any architectures anywhere on Earth.  We provide many code examples illustrating this design pattern.

Please also note that Horizon Edge machines may be single-tenant or multi-tenant (allowing guest code to be securely deployed, enabling collaboration with partner companies).  An appliance built by one manufacturer, for example, could enable applications written by their partners to be deployed and run, securely sandboxed, along side their own appliance support code to provide partner services to customers.  That partner code could be deployed on a completely independent release cycle, but could also specify dependencies on particular releases of the appliance vendor code as necessary.

Software design for edge machines must consider factors such as supporting multiple hardware architectures and constrained platforms, microservice components and dependencies, network reliability issues, trust and access, and typically the ability to customize individual components for a variety of deployment situations.

## Overview

This document will walk through the concepts underlying the Horizon Edge technologies and processes, as follows:

 * [Creating, Testing, and Containerizing Your Code](Edge-Development-Concepts.md#creating-testing-and-containerizing-your-code)
 * [Signing, Publishing, and Deploying With Horizon Edge](Edge-Development-Concepts.md#signing-publishing-and-deploying-with-horizon-edge)
 * [Registering Horizon Edge Machines](Edge-Development-Concepts.md#registering-horizon-edge-machines)
 * [How Horizon Works](Edge-Development-Concepts.md#how-horizon-works)
 * [Edge Software Design Principles](Edge-Development-Concepts.md#edge-software-design-principles)
  
## Creating, Testing, and Containerizing Your Code

Horizon Edge currently mandates the use of Docker containers for software deployment.

Docker containers were selected for development because they are highly flexible.  Developers are able to code in almost any programming language or combination of languages, and they can rely upon the OS support services of almost any Linux distribution.  As long as the resulting code can be packaged into a Docker container, it can be deployed by the Horizon Edge.  To support smaller IoT edge machines and in general for speed of deployment and update, it is best if your IoT edge software is compiled (e.g., from Go, or C) or has small language support libraries (e.g., Bourse Shell, or Bash).  It's also best if your code is packaged with a small Linux base distribution (e.g., BusyBox, Alpine, or another “lite” distro).  Note however that interpreted languages or those with large language support systems (e.g., Python, PHP, Node.js, C++, Java) and full size linux desktop distros (e.g., ubuntu, RHEL, Raspbian) are also supported as long as your edge machines have appropriate hardware to run them.  There is some discussion of the pros and cons of this in the [Edge Software Design Principles section](https://github.com/open-horizon/examples/blob/master/edge/doc/Edge-Development-Concepts.md#edge-software-design-principles) at the bottom of this document.

### An Example Program

An example program consisting of two containerized services is provided.  You may find it helpful to copy this example and modify it to create your first Horizon Edge deployment.  Let's take at this example code, see how it is built into a container, and learn how it will receive its initial configuration and credentials. The Horizon [Edge Developer Quickstart Guide](Edge-Developer-Quickstart-Guide.md) will guide you step-by-step through the deployment of this example code on Horizon Edge with the IBM Watson IoT Platform.

![Steps](images/Steps.png)

Exactly which local hardware will be accessible to your code, what configuration variable values will be provided to your code, and exactly which other services will be reachable from the sandbox where your code will run, is all controlled by systems external to your code.  Those systems will be discussed later in this document.  Note that although you may choose to deploy only your own services on your edge machines, you should also be aware that Horizon Edge also enables you to run IBM- and third-party-provided services to support your code.  Horizon also enables a multi-tenant environment so you could also safely run partner applications, sandboxed along side your own code.  There's more on that later too.

![Multi-Tenant](images/MultiTenant.png)

You can find the code for the example services, here:
	[https://github.com/open-horizon/examples](https://github.com/open-horizon/examples)

You can clone this repository using HTTPS, explore the directory structure, and read the example source code.  If you find an example in our examples repo that is particularly applicable to you, then you can jump right in at the hzn dev phase of the Quistart Guide.

There are two particular Horizon Service implementation directories in our examples repo that we recommend you visit.  The first one, in the “edge/services/cpu_percent” subdirectory is a simple example Horizon Service implementation that reads the CPU consumption and makes it available to other local Horizon Services by providing a REST API.  That "cpu" service (as it advertises itself) is then used by the other example Horizon Service implementation in the “edge/wiotp/cpu2wiotp” subdirectory, called "cpu2wiotp".  This second service consumes the CPU load data and sends it to the IBM Watson IoT Platform (WIoTP).  These two programs are each packaged as separate Horizon Services. They each consist of a single Docker container with one program running alone with its container.  Note though that a single Horizon Service may contain multiple Docker containers, and each Docker container may contain multiple process instances, if that is useful to you.

These example programs are both just short *shell scripts* written in the Bourne shell language (the simpler predecessor of Bash).  Of course, a single program could have been written and packaged into a single container instead to perform this same function.  However, this structure was chosen for the example code to illustrate the flexible "microservice" design pattern that is recommended in the Horizon Edge environment.  Building small, independent and easily composable code containers makes testing, deployment and software update scenarios more flexible.  It also encourages code re-use.

When you view the source code, notice that configuration variables are passed to the code by the parent shell through the process environment. For example, "cpu2wiotp" requires appropriate WIoTP credentials so it can communicate to the cloud so these are passed in the environment.  It is recommended that wherever possible you should develop your Horizon Services so they can be customized for various deployment situations by means of the environment variables they receive.

Also notice that your Horizon Service code can provide REST APIs to other Horizon Services running locally, as long as they are deployed as part of the same software deployment pattern.  In this case, the "cpu" service is deployed with the network name "cpu" onto the same Docker virtual private network with all of the other containers in its deployment pattern.  This means that other containers deployed in the same pattern may reach the "cpu" container by simply using the network name, "cpu".  For example, the "cpu2wiotp" container uses this URI to access the "cpu" container's REST API on port 8347: "http://cpu:8347/v1/cpu".  Any other containers running on the host outside of this deployment pattern would not be able to reach the "cpu" container.

Note that Services can be configured to have hardware access (or not) and access to operating system utilities (or not).  By granting special privileges to your Services you can enable them to read hardware sensors (e.g., cameras, microphones, temperature sensors, etc.) or to operate actuators (e.g., speakers, LEDs, solid state relays, motors, etc.), or to perform privileged operations in the host operating system.

Communicating from a Horizon Service container to the outside Internet can done in the usual ways.  It is recommended that Edge devices use encrypted communications with remote hosts.  It is also recommended that Edge devices be tolerant of network outages (which are common on small and remote devices).  The WIoTP implementation of Horizon Edge simplifies these considerations by enabling containers to communicate in plaintext over MQTT on the docker private virtual network to a local WIoTP agent container.  That local WIoTP agent container then implements store-and-forward services to mitigate the impact of network outages, and it encrypts all communications between the agent and the cloud.

The example code provides a template Horizon Service definition files.  These files uniquely identify the Service (through the combination of its "specRef", "arch"itecture, and "version") and identify its constituent containers.  The definition file also contains information about how the Service containers are to be deployed.  Most of the options available in the underlying Docker commands are available here.  Please consult the [deployment configuration reference](https://github.com/open-horizon/anax/blob/master/doc/deployment_string.md) for full details.

It is recommended that you follow through the [Edge Developer Quickstart Guide](Edge-Developer-Quickstart-Guide.md) to build, test, containerize, sign, publish and deploy this example code.

![Connections](images/Connections.png)

Note that this example code can be run directly in a host shell on your edge machine (if you manually set the required environment variables).  However, appropriate (very small) Dockerfiles are also provided here for various hardware architectures.  These enable you to instead build and run docker containers (which will ultimately be required for the production Horizon Edge environment).  Tools are also provided that enable the Horizon Agent to orchestrate a local deployment of your containers (closely imitating the production environment).  If you require more information about Docker containerization, or Docker registries, there are many excellent resources available on the Internet to help you with that.

A typical development workflow for Horizon Services is to begin by developing and validating your code locally in a shell on your development host, without containers.  Then when ready, packaging your code into containers and manually deploying and testing those containers locally on your development host.  Then you can push them to the public Docker registry, or a secure private registry like the IBM Bluemix Container Registry.  Details on how to use a private Docker registry are here:
    [https://github.com/open-horizon/examples/blob/master/edge/doc/Container-Registries.md](Container-Registries.md)

At that point you will want to re-validating everything using the "hzn dev" tool to perform a local deployment on your development host (sandboxing and passing environment variables like the production system will). Then finally you can test on a reduced set of edge nodes (anywhere on earth) deployed through the Horizon Edge production system.  Once you are confident in all of that testing, your containers can be deployed to your full set of edge nodes.  This typical development workflow is illustrated in the diagram below:

![Work Flow](images/WorkFlow.png)

As noted previously, all Docker images that will be deployed via Horizon must be cryptographically signed before they are uploaded to the Horizon Exchange (and their signatures must be verified before any Horizon Agent will run them).  Your software Deployment Pattern will tell Horizon which Services (and therefore which containers) should be run on which Edge machines, and it will reference the container hash, and the public key for your signature to enable subsequent verification.  By checking the hash and verifying the signatures of your docker images, the Horizon Agent on your Edge machines can verify every container it downloads and be confident that it has not been tampered with.  Similarly, the configuration data (i.e., environment variable values) embedded in your Deployment Pattern for your Services must be signed to also safeguard it from tampering.  The tools Horizon provides for signing are covered in the next section.

## Signing, Publishing, and Deploying With Horizon Edge

Now that you understand how to write, build and containerize Horizon Service code, let's take a look at the Horizon tools provided to deploy your code locally simulating the production environment, and to sign and publish your code and configuration for the production environment.

First a little background on the "hzn" tool.  When you install the "horizon" package on your edge node (e.g., following the process in the Quickstart guides) this will install hzn too. Hzn is primarily a wrapper for the REST APIs provided by most of the Horizon components.  Instead of finding the right API, determining its URL, and running a "curl" command to access it, you can more easily use the hzn command.  The hzn command has subcommands for interacting with the Horizon Exchange or the local Horizon Agent, etc.  Hzn also offers detailed online help information for all of its commands and arguments.  Try "hzn --help" for a start, but also remember that you can pass "--help" to and full or partial hzn command.  For example, "hzn exchange --help" will give you help about all of the Horizon Exchange commands offered.  With the hzn command you can interrogate Horizon about the state of most of its components.  You can also use it to interact with these components to create, update or delete objects in the domains of these components.

Let's look specifically at the "hzn dev" subcommand.  The hzn dev subcommand is designed specifically to help developers create and test code for Horizon Edge.  If you follow through the [Edge Developer Quickstart Guide](Edge-Developer-Quickstart-Guide.md) you will see this tool in action.  It helps you to create the necessary meta-data files describing your services to Horizon, and helps you verify them.  The "hzn dev service start" and "hzn dev service stop" commands let you use the local Horizon Agent to start and stop your Horizon Service implementations (complete with their dependencies) in an environment simulating production.  The appropriate environment variables will be set, the appropriate Docker virtual private network will be created, and your service container names will be assigned on that network.

The "hzn key create" will help you to create an asymmetric key pair to enable cryptographic signing of your Horizon Service code.  The "hzn util sign" command can then be used to actually sign it when you are ready to deploy.  Similarly, "hzn util verify" can be used to verify that signature.  To actually publish your Service to the Horizon Exchange you will use "hzn exchange service publish".  Then you can verify your Service in the Exchange with "hzn exchange service verify".  All of these commands, and more, are used in the [Edge Developer Quickstart Guide](Edge-Developer-Quickstart-Guide.md).

The last remaining task on the development side is to define a deployment pattern (or patterns) for sets of your Horizon Edge nodes.  Your Edge nodes will be configured with an IBM Watsopn IoT Platform device or gateway Type (as will be discussed in the later section on node registration).  Watson IoT Platform device/gateway Types correspond exactly to Horizon Edge Deployment Patterns,

Creating a Deployment Pattern consists of identifying which Horizon Services should run together on devices of this Type, with what sort of access, and which environment variables should be provided to configure them.  This is done by creating a JSON metadata file to detail your Deployment Pattern, and then using "hzn pattern" commands.  Again, this process is shown in the [Edge Developer Quickstart Guide](Edge-Developer-Quickstart-Guide.md).

Although the Watson IoT Platform instance of Horizon Edge currently does not directly expose this capability, Horizon was also designed to be multi-tenant, enabling multiple sets of software to be run in independent sandboxes on the same Edge host.  This could, for example, enable a manufacturer of appliances to have their own core software running in one sandbox, with high privilege and with full access to the hardware and operating system utilities, while also enabling them to run one or more partner applications.  Those partner applications could have individually scoped access, enabling each to use only those services and resources specified.  If you wish to do this in the context of the Watson IoT Platform you will need to discuss this with your account representative.

## Registering Horizon Edge Machines

Now that you understand the developer side of things -- how to create your code for Horizon Edge and include it in your Deployment Pattern -- let's look at how Horizon Edge machines are configured to run your Deployment Pattern.

To begin you will need to install the Horizon software packages on the Edge node (e.g., by following the ["Adding Devices" instructions](Adding-Devices.md), or by working your way through the [Edge Quickstart Guide](Edge-Quick-Start-Guide.md).  Horizon packages are available for a variety of x86, ARM, and Power architectures as detailed on the Adding Devices page.

Installing Horizon will start a local Horizon Agent on your Edge node.  It will also install the "hzn" CLI described in the previous section.  Before a new node can join the Horizon Edge, it must be registered.  The [Edge Quickstart Guide](https://github.com/open-horizon/examples/blob/master/edge/doc/Edge-Quick-Start-Guide.md) will lead you through that process, setting up the local Horizon Agent on your node and registering your node in the Horizon Exchange.  You will need to provide your Watson IoT Platform Organization name, and the device or gateway Type of this node (which also defines the software Deployment Pattern for the node, as discussed in the previous section).  You must also supply the unique node identifier, and authentication token for the node when you register.  Normally all of this is done with the "wiotp\_agent\_setup" command.

At the point of registration all of the required configuration variables for all of the services in the Deployment Pattern for this machine Type must have values specified.  They may either be specified in the Service definition file provided when you published the Service with the Horizon Exchange, or you must provide them in the user input data for the Service when you register the Edge machine with the Horizon Exchange.  For more information, please read this [detailed discussion](https://github.com/open-horizon/anax/blob/master/doc/attributes.md) of these configuration variables, or attributes.

Registering your node will place an entry for the node into the (remote, centralized) Horizon Exchange, and will enable the node to communicate using the Horizon Switchboard.  Once this is done, the Horizon AgBots for your Organization will discover the node using the Exchange, and will begin communicating with it to create Agreements to run software on the node.  Once the agreement handshake is complete, the local Horizon Agent will download your code containers, verify their cryptographic signatures, and then run them in an appropriate sandbox.  That sandbox will contain an appropriate Docker virtual private network that the containers can communicate over, and the process environment of each container will contain the configuration variable values you specified for this Deployment Pattern.  These processes, and the Horizon components involved, are described in more detail in the next section.

Note that once the node has been registered, you never need to return to the node.  Horizon will fully automate the lifecycle management for your Horizon Services code from then onward.  You can set up a Continuous Integration system to build new versions of your Services and push them to your preferred Docker registry.  You can also set up a Continuous Deployment pipeline to update your Deployment Pattern in the Horizon Exchange.  The Horizon AgBots, and Horizon Agents will detect any such changes then rapidly and securely orchestrate the appropriate software update process on all of the Horizon Edge nodes to which that Deployment Pattern has been assigned.

## How Horizon Works

The first section of this document covered developing for Horizon: how to write your code, package it as required, and then deploy it using Horizon Edge.  The second section covered registering an Edge machine so Horizon Edge can manage the software on that machine.  Those are the external interfaces of Horizon Edge that you will be working with normally.  Now it is time to look deeper, to understand how Horizon Edge actually works.  Having insights into the underlying mechanisms can help you to diagnose problems when something is not working as expected.

In general the activities of Horizon Edge are driven by the metadata you provide in JSON-formatted files describing your Deployment Patterns, the Services that comprise them, and the containers within those Services.  Of course, you must also provide the public keys corresponding to the private keys you use to cryptographically sign everything.  If your containers are stored in a private container registries, you will also need to provide access tokens so they can be retrieved. To enable communication with the Watson IoT Platform you also need to provide appropriate credentials (typically your organization ID, device or gateway types, IDs and tokens, and possibly API keys and tokens).  This data is consumed by the main software components of Horizon Edge: the centralized Switchboard and Exchange, and the Agent and Agreement Bot (or "AgBot") processes running on Edge machines.  The Agents and AgBots are built from the same ["anax" codebase](https://github.com/open-horizon/anax) and they are the primary actors in this system. In contrast, the Switchboard and the Exchange are centralized services scaled out in the cloud to perform specific infrastructure functions supporting the Agents and AgBots.

![Overview](images/Overview.png)

Horizon Edge machines typically run only the Agent process.  The Agent process represents its Edge machine to other Horizon software components, and it performs all automated Horizon actions that occur locally.  The Agent presents a [REST API](https://github.com/open-horizon/anax/blob/master/doc/api.md).  You can interact directly with this API to interrogate the Agent's status or to take actions (e.g., install a cryptographic public key).  You may also interrogate the local Agent process by using "hzn" commands on its node, including: "hzn node ...", "hzn key ...", "hzn agreement ...", "hzn metering ...", "hzn attribute ...", "hzn service ...", "hzn status ...", and more.  Use the "--help" to get more information about any of these commands.

Horizon Edge machines may also run AgBot processes. That is, Edge machines may run just an Agent, or just an AgBot, or it may run both. There are typically far fewer AgBots than Agents, and AgBots are often deployed in the cloud (as they are in the Watson IoT Platform case).  Each AgBot is responsible for one Deployment Pattern.  Deployment Patterns each correspond exactly to one Watson IoT Platform device or gateway Type.  The AgBot for a particular Deployment Pattern repeatedly polls the Horizon Exchange to discover new Edge machines that have registered to run its Deployment Pattern.  When it discovers such an Edge machine it reaches out to the Agent on the machine to propose a formal "Agreement".  AgBots and Agents negotiate their Agreements over the Horizon Switchboard.  The AgBot and any Agent with which it has formed an Agreement then work closely together to coordinate the distribution, verification, installation, and update of the software in this Deployment Pattern on the Agent machines. Each AgBot also continuously polls the Horizon Exchange to ensure that it promptly learns of any changes to its Deployment Pattern.  When the pattern changes, the AgBot will again work with all of the corresponding Agent processes to orchestrate software changes on all of the machines of its Type.

The AgBot also presents a [REST API](https://github.com/open-horizon/anax/blob/master/doc/agreement_bot_api.md).  You can interact directly with this API to interrogate the AgBot's status or to take actions.  You may also interrogate the local AgBot process by using "hzn" commands on its node, e.g.: "hzn agbot ...".  Use the "--help" to get more information about any of these commands.

In the Watson IoT Platform instance of Horizon, AgBots are provisioned and configured automatically for you.  So normally all you need to do is provide your metadata to the Horizon Exchange, and register your Edge machines, and the automated systems will take care of everything else.

The Horizon Exchange enables Horizon AgBot processes to discover Horizon Agent instances on remote Edge machines.  It does this my accepting Horizon Agent registrations for their Edge machines, and maintaining them in a local database that AgBots can query.  The Exchange is also the central authority on Software Deployment patterns and their constituent parts, Services.  AgBots also query the Exchange for this data.  Horizon participants' interactions with the Horizon Exchange occur through its [REST API](https://console.bluemix.net/docs/services/IoT/reference/api.html#api_overview).  You may also interact with the Horizon Exchange through local "hzn exchange ..." CLI commands which will make those REST API calls for you (see "hzn exchange --help" for more info.

The Horizon Switchboard facilitates secure private and anonymous communications between Horizon participants.  It might seem more ideal to use a purely peer-to-peer messaging system for communication between participants.  However a key Horizon requirement is that complete privacy must be maintained until all communicating participants expressly desire to share personal information (such as their IP addresses).  The Horizon Switchboard leverages asymmetric key cryptography to achieve this goal, enabling Edge machines to register providing only the *public* key from their asymmetric key pair.  When any Edge machine wishes to communicate with any other, they need only know the other's *public* key, and they only need to identify themselves with their own *public* key.  Their communications through the Switchboard will all be encrypted using an independently derived shared symmetric key. How do the two participants independently derive the same symmetric key?  Each party used their own *private* key combined with the other party's *public* key to derive the same shared *symmetric* key (e.g., using a [Diffie-Hellman](https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange) key derivation algorithm). By doing this they are able to encrypt their messages such that even the Horizon Switchboard is not able to eavesdrop on their messages. To be more secure, the parties can use their shared symmetric keys to generate a *series* of shared symmetric message keys so that no two of their messages are ever sent using the same key.  The initial communications between Edge machines, to negotiate Agreements, can therefore be conducted with complete anonymity (only the parties' public keys are exposed).  Once the participants are in an Agreement they can share their IP addresses and communicate peer-to-peer, no longer involving the Horizon Switchboard.

At this point you have learned about the mechanics of software development for Horizon Edge, and you understand how the underlying "control plane" of Horizon Edge works.  You understand the role of the Horizon Agent on each Edge  machine, and the role of the AgBots that reach out to them to drive software deployment and update.  You also understand how the Horizon Switchboard and the Horizon Exchange preserve participant anonymity and privacy while enabling discovery and agreement negotiation (and how the Exchange manages software Deployment Patterns for particular machine Types).  Now let's take a look at the "data plane" side of Edge development.  The Horizon team has defined some principles and key concepts that are recommended for the data plane side of Edge software design, and these are covered in the next section.  The Watson IoT Platform provides many services to simplify the application of these principles, and the implementation of best practices for the Edge.

## Edge Software Design Principles

Horizon Edge treats all Internet endpoint as Edge machines.  That is, powerful web server hardware, or "virtual machines" (VMs) in a cloud data center, and small "Internet of Things" (IoT) devices with IP addresses are all treated symmetrically by the Horizon control plane.  The requirements for the data plane software is not the same for each of these platforms.  Small machines often tend to be deployed in environments where basic resources such as power supply and Internet connectivity can be unreliable.  They also tend to be constrained in terms of CPU and GPU capabilities, memory, storage, and network bandwidth.  They also tend to run on a much greater variety of CPU hardware architectures (ARM, MIPS, Apple, Atmel, Tensilica, etc.).  These factors imply a requirement for different software development design principles when developing for IoT devices.  Also, applications developed to communicate between very large numbers of machines over the public Internet have their own distinct design requirements.  For example, IoT applications supporting large numbers of IoT machines typically implement smaller numbers of cloud endpoints, globally distributed to keep latency low regardless of IoT device location, and with automatically scaled and load-balanced cloud services to communicate with them.  Although the cloud side of data plane design is well known from decades of experience with web services, the IoT side is still evolving.  IoT Edge environments present new and unique challenges and the goal of this section is to share the Horizon team's IoT Edge design principles and best practices.

### Microservices

The first principle we want to recommend is the use of [microservices](https://en.wikipedia.org/wiki/Microservices).  The microservices architecture began to emerge as a new software development paradigm early in this decade.  Microservices are small, configurable, and composable software components that communicate with other microservices, usually over HTTP, and usually by means of [RESTful APIs](https://en.wikipedia.org/wiki/Representational_state_transfer).  Another common communications protocol for microservices is [MQTT](https://en.wikipedia.org/wiki/MQTT).  Keeping microservices components small and loosely coupled improves modularity, fosters rapid parallel development and continuous deployment.  The microservices architecture also simplifies testing, and continuous refactoring of these components.  The Horizon Edge is designed to simplify development and deployment of microservices.  Build your containers as individual components, compose them freely into configurable Horizon Services, and compose your Services into Deployment Patterns.  Each of your Services can be independently updated then fully automatically deployed to all of your Edge machines without touching your other Services.  This creates a very [Agile](https://en.wikipedia.org/wiki/Agile_software_development) development environment for your Edge code.

In Horizon, we also recommend designing two different classes of Service.

*Device Level Services*

First, design low level Horizon Services that provide and control access to hardware components, and operating system services.  These low level Services must run with elevated privileges to get the access they need, so they must be developed with the greatest care and should be small, and they should require the fewest changes.  You could think of these low level Services like device drivers for Horizon Edge machines and they should be given only the least amount of access that they require to perform their specific small and focussed single function.  They can in turn enable shared access or exclusive access to underlying hardware or OS services through APIs they expose, and they will do this only under the control of Horizon Agreements.  These Services should typically only expose their APIs on the local machine, and only on interfaces that are accessible only on the virtual private networks created by Horizon for them.  These Services should not normally communicate with any entities outside of the machine where they run.  These Service implementations might be built by third party software vendors, or they may be simple wrappers built on top of device support code provided by hardware vendors.

*Other Services*

Your business logic can then be built into a Service that runs with less privilege, and which can be updated more frequently with less disruption to other software running on the Edge machine.  Each of these business logic Services can also be deployed with a separate Horizon Agreement, giving great flexibility for continuous deployment.  The primary software developer (e.g., the appliance manufacturer) and any partner organizations that are allowed to deploy software to the appliance can develop, evolve and test their business logic code completely separately and then deploy them independently to the Edge without synchronizing they release deployment schedules.  

### Managing Dependencies

One consequence of using a microservices architecture is that individual components typically have dependencies on the services of other components.  In Horizon, you declare these dependencies explicitly in your Service definition files.  Horizon will then start up the containers that implement your Service dependencies first, before starting the containers in Services that use them.  However, this is not sufficient, since complex services can take unpredictable amounts to time to come up and be completely ready to serve clients.  It is therefore wise to handle the unavailability of Services you depend upon, at least during the startup of your Service.  For example, you may wish to poll repeatedly until you discover your dependencies are available before starting your Service.  Of course, your dependencies may never come up or they may come up and fail, and you will have to decide how to handle those scenarios as well.

### Avoid Persistent State

As much as possible it is recommended that you design your components to be *stateless*.  That is, whenever your component starts up it should assume as little as possible about the past and rely only upon its current configuration and whatever it can glean from the host environment within its sandbox.  Being stateless helps to make your Services resilient in the event of a reboot, or power outage, or other significant disruption on the host.  If you absolutely must preserve some state between restarts of your Service, or across reboots of your host, a directory is mounted read/write in your container with the path `/service_config` where you can write state.  Note that this state will be lost if the agreement is ended or renegotiated for any reason (i.e., part of the cleanup at the end of an agreement is the removal of that directory and all of its contents).

Note also that if multiple threads, or multiple processes, will be accessing any state files in the provided directory, then to ensure your data integrity you must take care to perform *atomic* writes.  For example, rather than writing directly to a file to update it, you can write the new version of the file into a temporary file, then close that file and rename it to the target filename (unlinking any previous version of the file with that name).

### Coding For Network Unreliability

Small IoT devices often have intermittent network connectivity (e.g., being deployed in an environment with unstable power, or being deployed in a non-industrial WiFi environment).  It is wise for IoT developers to design for their software to compensate for this.  That is, IoT Edge software should assume that the network will sometimes be unavailable.  When the network is unavailable, the IoT device must continue to behave appropriately.  For example, a household thermostat cannot simple cease to function when the network is unavailable.  It must instead continue to behave in a reasonable manner until connectivity is reestablished.  Perhaps more poignantly, an embedded medical device must continue to provide its life-sustaining services regardless of network connectivity.  Typically this means that some local "intelligence" must be built into the IoT Edge software that controls s]the behavior of its systems while offline.  If the IoT Edge device normally reports data to a remote network endpoint (e.g., a typical centralized IoT cloud service) then the IoT Edge software will likely need to store that data until network connectivity is restored, then forward all the stored data when it can.  Horizon Edge software running in the Watson IoT Platform instance of Horizon Edge does not need to worry about store-and-forward functionality because this is a built-in feature of the IBM IoT-core Horizon Service that is deployed on every Edge machine.  Your code simply needs to send the data to the local IoT core, over the virtual private network it shares with the IoT-core.  The IoT-core will then send it on to the Watson IoT Platform cloud servers.  Whenever the cloud servers are inaccessible for any reason, the IoT-core will cache your data locally for later forwarding when connectivity is restored.

### Secure Communications

Another common characteristics of the networks connecting IoT Edge machines is they may not be secure.  Typically IOT applications involve devices in the field communicating over the public Internet to cloud hosts.  Of course, open communications across the public Internet may susceptible to interception by eavesdropping devices, or malicious software running on access points, bridges, switches, or routers along the route.  It is therefore recommended that all communications leaving the IoT Edge machine should be encrypted.   Horizon Edge software running in the Watson IoT Platform instance of Horizon Edge does not need to worry about encrypting communications to the cloud because this is a built-in feature of the IBM IoT-core Horizon Service that is deployed on every Edge machine.  Again, your code simply needs to send the data to the local IoT core, over the virtual private network it shares with the IoT-core.  The IoT-core software will then send it over an encrypted connection to the Watson IoT Platform cloud servers.

### Network Bandwidth Considerations

The Internet often seems ubiquitous and able to take whatever data our IoT devices may send.  However, the number of machines attached to the Internet is rapidly increasing.  Also, their ever increasing computing power and the ever improving resolutions of their input devices (e.g., HD cameras) are producing huge volumes of data.  The result is far too much data data being produced far too quickly and from far too many endpoints for all of it to be sent to any set of cloud endpoints, no matter how globally distributed or scaled out they may be.  Instead, IoT devices need to be designed to send a relatively small amount of relatively higher information content data to their cloud targets.  Often this means that some local "intelligence" on the IoT device needs to monitor its inputs and perform tasks like summarizing, classifying, and detecting events of interest.  [Neural Network](https://en.wikipedia.org/wiki/Artificial_neural_network) (NN) algorithms running on the IoT machine can be very effective at these sorts of tasks.  Typically these NNs will need to be *trained* on more powerful systems, like the IBM Power 9 systems with NVIDIA GPUs that are available in the IBM cloud (and that are used for IBM Watson).  However, once trained these NNs can often be used for *inferencing* tasks on small IoT devices in the field.

### CPU, GPU and Memory Consumption Considerations

IoT machines typically have CPUs with minimal capabilities.  Often they are single-core 32-bit CPUs running at clock rates in the MHz range with a few MB of RAM.  Some are far less computationally capable.  Some have GPUs that can be used for computation but most do not.  These constraints imply that CPU, GPU and RAM consumption are important considerations in the design of IoT Edge software.  This is especially important if the IoT Edge machine needs to achieve any performance guarantees for local operational performance.  Horizon exposes the Docker functionality for constraining containers, so you can use these features to ensure that containers do not consume excessive amounts of these scarce resources.

These constraints also could also be important considerations when selecting the operating system variant, programming language, and support libraries you choose for your IoT Edge software.  In particular, small Linux distributions generally offer significantly better memory consumption characteristics than their larger counterparts.  So when designing your Docker containers you may wish to explore the possibility of using busybox, alpine, or other small Linux distributions (versus typical larger distributions like debian, RHEL, or ubuntu) minimize resource consumption.  If you can use the smaller distributions your containers will also be smaller, so they will download faster as well, meaning software updates will be faster.  Also, the choice of programming language is important here as well.  Small languages like the Bourne shell, and compiled languages like C, or Go generally are preferable to large, higher level or interpreted languages which tend to have huge library support systems.  Go is an especially nice language for IoT Edge development because it is easy to compile small and completely self-contained binaries that have all library dependencies included in a single file.  Many of the Horizon example programs and Proofs of Concept (PoCs) are written in either the Bourne Shell language, or its newer cousin Bash. or in Go.

### Minimizing Container Sizes

Whichever Linux distribution you select, and whichever programming language and libraries you choose, it is important to minimize the size of the resulting Docker container.  Smaller containers deploy more rapidly and consume less network bandwidth.

Some simple techniques can very significantly shrink the sizes of your production containers.  For example, when using "apk add ..." to install code upon your alpine-based container, you can use "apk --no-cache --update add ..." instead.  This avoids storing the package cache, which is not needed at runtime in production for your container.

Also note that in your Dockerfile, deleting files in a subsequent layer (each Dockerfile statement creates a new layer for the resulting container) may not have the effect you expect.  Deleting in a later layer does not actually remove the space from the resulting image file (because everything in all of the previous layers is still included).  There are a couple of ways to get around this common problem:

The first is to "squash" the resulting final image.  To squash a Docker container image, use "docker save" to save it into a tar file, and then immediately use "docker load" to reload the image. If you don't want to bother squashing your images, you can use an alternate technique.  Instead reduce layer issues by creating fewer layers.  You can, for example do many steps (installing then removing) all in the same RUN statement, separated by "&&".  By doing this, all of the changes on that line are all done within a single layer (creating temporary files, and then immediately removing them within the same layer prevent them from taking space in the final image).

Each of those techniques can save large amounts of space in your container images.

Another technique that is important is to avoid build tools, or build steps, in your image.  The best practice here is for any build scripts or makefiles to be run in a separate docker container to build the runtime artifacts needed (e.g., to compile and link binary code for installation and deployment).  Then in your production container, just copy the built artifacts (e.g., executables, dynamic libraries, etc.).

### Software Configuration and Customization

The last significant design principle we want to emphasize for IoT Edge software design is configurability.  By building small microservices and designing them to be reusable in a variety of contexts by means of configuration data provided in environment variables, you will encourage code re-use and in the long run improve stability.  Also by enabling some data to be provided externally, you eliminate the need to hard-code things like credentials into your containers.  Instead, your cryptographically signed configuration variable settings, managed by the Horizon Exchange, can contain this data.  With this arrangements your containers can be exposed without risk to your credentials.  You can also change these credentials (or other configuration) whenever needed without updating your code.

Horizon enables configuration to reach your process environt in three ways, through a combination of Adjustable environment variables, and Hard-Coded environment variables, as shown in the diagram below:

![Definition Files](images/DefinitionFiles.png)

Please note that the Adjustable environment variables shown in the diagram must be **individually** set for each IoT edge machine at the moment the machine is being registered with the Horizon Exchange.  Every one of these Adjustable environment variables must be given a value **at registration time** (unless default values were provided).  It is best to minimize the use of these in order to simplify devcie registration.

Hard-Coded values in Service definition files will have the same value for all machines using that Service, **unless they are overridden** by a Deployment Patterns that uses the Service.

Hard-coded values in the Deployment Pattern definition are like Hard-Coded values in the Service definition except that **they may also override** the Hard-Coded values set in the Service definition file.  Hard-Coded values set in a Deployment Pattern will have the same values on all machines using that Deployment Pattern.

Note also that the Hard-Coded set of environment variable names and the Adjustable set of environment variable names **must be disjoint**.

## Next Steps

If you haven't already done so, it is recommended that you next run through the [Edge Quickstart Developer Guide]([https://github.com/open-horizon/examples/blob/master/edge/doc/Edge-Developer-Quickstart-Guide.md]).  It will guide you through the process of defining Watson IoT Platform credentials, then building some example code, then deploying that code to your Horizon Edge machine by means of a Deployment Pattern.

Some additional edge software development guidelines are here: 
* [https://github.com/open-horizon/examples/blob/master/edge/doc/Edge-Service-Development-Guidelines.md](Edge-Service-Development-Guidelines.md)

For further reading, explore the open source Horizon project:
* [https://github.com/open-horizon](https://github.com/open-horizon)

You may also find our [Frequently Asked Questions](Frequently-Asked-Questions.md) page to be helpful.

If things go wrong while you are trying to use Horizon Edge, please try our [Troubleshooting Guide](Troubleshooting.md).

To discuss the Horizon Edge development process, or to pose questions to the team, visit us at:
* [https://developer.ibm.com/answers/smart-spaces/17/internet-of-things.html](https://developer.ibm.com/answers/smart-spaces/17/internet-of-things.html)

